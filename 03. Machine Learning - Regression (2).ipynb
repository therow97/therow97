{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38acb167-b14e-4810-993c-f63e8a62ab65",
   "metadata": {},
   "source": [
    "# Notebook 3:  Regression\n",
    "\n",
    "<font color='red'>**Wichtig**:  \n",
    "Dieses Notebook muss spätestens am Mittwoch den **22.12.2021** über die zugehörige Aufgabe auf Moodle abgegeben werden.</font>\\\n",
    "**Kompilieren** Sie vor der Abgabe das Notebook noch einmal **komplett** und speichern Sie es dann ab (_Kernel_ --> _Restart Kernel and Run All Cells_).\\\n",
    "Bevor Sie Ihr bearbeitetes Notebook hochladen, **benennen** Sie das Dokument bitte wie folgt:\\\n",
    "**_Nachname_Matrikelnr_Notebooknr.ipynb_**\n",
    "\n",
    "Führen Sie nun nach und nach den unten stehenden Code aus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ba11e-acc4-41a7-a642-192940f68dc5",
   "metadata": {},
   "source": [
    "## Import gebräuchlicher Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd14468-f8f0-4076-ab01-189a834a4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Zeigt Plots direkt im Notebook an:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec73182-0a61-4a99-b968-a07906d53150",
   "metadata": {},
   "source": [
    "## Beispiel Regression\n",
    "\n",
    "Quellen:\\\n",
    "Müller, A.C. & Guido, S., Einführung in Machine Learning mit Python - Praxiswissen Data Science, O´Reilly (2017)\\\n",
    "https://github.com/amueller/introduction_to_ml_with_python\n",
    "\n",
    "Als Beispiel für eine Regressionsaufgabe werden wir vorerst auf einem generierten Datensatz arbeiten. Zu Zwecken der Visualisierung besteht dieser erste Beispieldatensatz aus nur einem Feature X und den Labels y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6a158-e289-498b-aa62-320a04768bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz generieren\n",
    "def make_wave(n_samples=100):\n",
    "    rnd = np.random.RandomState(42)\n",
    "    x = rnd.uniform(-3, 3, size=n_samples)\n",
    "    y_no_noise = (np.sin(4 * x) + x)\n",
    "    y = (y_no_noise + rnd.normal(size=len(x))) / 2\n",
    "    return x.reshape(-1, 1), y\n",
    "\n",
    "X, y = make_wave(n_samples=60)\n",
    "plt.plot(X, y, 'o')\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de49835e-23d5-4db8-90f6-d48ce7250064",
   "metadata": {},
   "source": [
    "### Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a46bab-e68d-4ab3-9d7b-21927d5a6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Trein-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Trainiere lineare Regression\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Der y-Achsenabschnitt (intercept) wird in der Implementierung gesondert betrachtet\n",
    "print(\"Gewicht w[0]: %f  y-Achsenabschnitt b: %f\" % (lr.coef_[0], lr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59683599-ba45-4ca4-a5b2-1c82f3b0db43",
   "metadata": {},
   "source": [
    "**Bemerkung**:\\\n",
    "Scikit Learn speichert alles was aus den Trainingsdaten berechnet wurde mit einem nachgestellten Unterstrich, um es von Parametern zu unterscheiden, welche vom User gesetzt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2167fe-19c7-48c6-84d3-604080986d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "line = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(line, lr.predict(line))\n",
    "plt.plot(X, y, 'o')\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_position('center')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['bottom'].set_position('center')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.set_ylim(-3, 3)\n",
    "#ax.set_xlabel(\"Feature\")\n",
    "#ax.set_ylabel(\"Label\")\n",
    "ax.legend([\"Modell\", \"Trainingsdaten\"], loc=\"best\")\n",
    "ax.grid(True)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b06f91-e19a-4b5b-a5fc-c135c4f161df",
   "metadata": {},
   "source": [
    "Schauen wir uns nun die Performance auf den Trainings- und Testdaten an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00379b8-cedb-49d6-bcad-46f14f47a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainingsscore: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Testscore: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb3602-6095-426b-b56d-4fda0e2fb76a",
   "metadata": {},
   "source": [
    "Ein Score von 1 ist das beste Ergebnis und ein Score von 0 das Schlechteste.\n",
    "\n",
    "Ein Testscore von 0.69 ist nicht so gut. Aber man kann sehen, dass Trainings- und Testscore nahe beieinander sind, d.h. das wir höchstwahrscheinlich eher Underfitting als Overfitting haben. (Die Gefahr für Overfitting ist bei eindimensionalen Datensätzen (d.h. nur ein Feature) verhältnismäßig gering, bei mehrdimensionalen Datensätzen (d.h. viele Featuures) ist die Gefahr viel größer.)\n",
    "\n",
    "Als Alternative zu diesem einfachen Datensatz wollen wir uns einen komplexeren Datensatz von Diabetes-Patienten ansehen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f22c6-11af-4046-90ec-f10d22756d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Features & labels\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "print(\"Dimension der Daten:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b46ce-6b55-4ec3-9d1b-e32d768fe939",
   "metadata": {},
   "source": [
    "Informationen zum Diabetes Datensatz sind hier zu finden:\\\n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset \\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "\n",
    "Der Datensatz enthält 10 verschiedene gemessene Werte von 442 Diabetes-Patienten. Die Labels/Zielvariable enthält ein quantitatives Maß des Krankheitsverlaufs über ein Jahr.\n",
    "Um den Datensatz komplexer zu machen, fügen wir das Produkt je zweier Spalten als neue Features hinzu (dies entspricht quadratischer Regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4efb0-9c51-41b5-aeb7-70816ee811d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "# Feature Engineering:\n",
    "X = MinMaxScaler().fit_transform(X)     # Skaliere Features zwischen 0 und 1\n",
    "X = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)     # Produkt je zweier Spalten hinzufügen\n",
    "\n",
    "print(\"Dimension der Daten:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33973da1-b003-4b80-9c37-a529b4df828a",
   "metadata": {},
   "source": [
    "Nun teilen wir wieder unsere Daten auf und trainieren unser Regressionsmodell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b5bf0-f5f1-4532-9e0c-abd67ebdb408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Trainiere lineare Regression\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Training & Test Score\n",
    "print(\"Trainingsscore: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Testscore: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc6746-6588-49b0-8440-e4eb02d93f3c",
   "metadata": {},
   "source": [
    "Der Testscore ist sehr schlecht, der Trainigsscore ist auch nicht gut, aber deutlich besser. Ein großer Unterschied zwischen Training- und Testscore ist ein Indikator für Overfitting. Um Overfitting zu vermeiden schauen wir uns nun regularisierte Regressionsmodelle an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f58b19a-bc07-4150-9c66-2a7e7c9c62b9",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "\n",
    "Schauen wir uns im Vergleich die Performance der Ridge Regression an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706fda6-552f-4b8d-a981-6c2fe0cb43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Trainiere Ridge Regression\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "\n",
    "# Training & Test Score\n",
    "print(\"Trainingsscore: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Testscore: {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc0cd5-7d3c-48e0-8967-78839dd9d553",
   "metadata": {},
   "source": [
    "Man kann sehen, dass der Wert des Trainingsscores niedriger und der des Testscores höher ist. Dies ist zu erwarten, da ein regularisiertes Modell besser generalisieren sollte und nicht so sehr overfittet.\n",
    "\n",
    "Ridge verwendet ohne eine Einstellung des Regularisierungsparameters, der hier alpha heißt, alpha=1.\n",
    "Erhöht man den Regularisierungsparameter alpha, so wird die Performance auf den Trainingsdaten schlechter aber der Testscore wird besser, d.h. das Modell generalisiert besser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b379c19-e535-4f46-96f0-2570072ca65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainiere Ridge Regression\n",
    "ridge = Ridge(alpha=10).fit(X_train, y_train)\n",
    "\n",
    "# Training & Test Score\n",
    "print(\"Trainingsscore: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Testscore: {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe10014-fdd9-4d1c-ba00-ac3d599b117e",
   "metadata": {},
   "source": [
    "Verkleinern wir alpha, so gehen wir mehr in Richtung des unregularisierten Modells. Testen Sie verschiedene Regularisierungsparameter aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcdb277-d9a6-45f3-a004-03a1ec3b2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainieren Sie Ridge Regression mit verschiedenen alphas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67e7e0-dca3-457b-9218-04f0cbf73c3d",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "\n",
    "Alternativ können wir Lasso Regression betrachten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690d1c6-a90b-4426-8c1d-29bfbbf8c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Trainiere Lasso Regression\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "\n",
    "# Training & Test Score\n",
    "print(\"Trainingscore: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"Testscore: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"Anzahl benutzter Features:\", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682dc391-9c0b-4521-a26c-3a30588ffa5f",
   "metadata": {},
   "source": [
    "Lasso performt schlechter auf den Trainings- und Testdaten. Wahrscheinlich findet hier Underfitting statt, es werden auch nur 9 von 65 Features verwendet.\n",
    "\n",
    "Auch bei Lasso ist der Standardregularisierungsparameter alpha=1. Schauen wir uns an, was passiert, wenn wir den Regularisierungsparameter alpha veringern. Wenn wir das machen, müssen wir auch den Standardwert von max_iter=1000 (maximale Anzahl der Iterationen) erhöhen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ce4b8-5393-4e7c-9558-9e31d13fd0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainiere Lasso Regression\n",
    "lasso001 = Lasso(alpha=0.5, max_iter=5000).fit(X_train, y_train)\n",
    "\n",
    "# Training & Test Score\n",
    "print(\"Trainingscore: {:.2f}\".format(lasso001.score(X_train, y_train)))\n",
    "print(\"Testscore: {:.2f}\".format(lasso001.score(X_test, y_test)))\n",
    "print(\"Anzahl benutzter Features:\", np.sum(lasso001.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e1622-1fff-4bbd-b054-bee3ec1ecc8a",
   "metadata": {},
   "source": [
    "Testen Sie auch für die Lasso Regression verschiedene Einstellungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf562382-4e09-4faf-8dd5-67adaf796c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainieren Sie Lasso Regression mit verschiedenen alphas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570078e7-b17b-4466-89a6-37ae95243950",
   "metadata": {},
   "source": [
    "Der Datensatz ist nur zum Ausprobieren und nicht sehr ergiebig. Aber es reicht um ein grobes Verständnis der Methoden zu bekommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5326685-5739-44f4-afb3-4e01c0435b8f",
   "metadata": {},
   "source": [
    "# Anwendung: California Housing Datensatz\n",
    "\n",
    "Für die Übungsaufgaben nutzen wir wieder den California Housing Datensatz.\\\n",
    "Quellen:\\\n",
    "http://lib.stat.cmu.edu/datasets/houses.zip \\\n",
    "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset \\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html\n",
    "\n",
    "**Erinnerung**:\n",
    "\n",
    "- **MedHouseVal:**  Median-Hauswert --> Label\n",
    "\n",
    "Die Features sind die folgenden:\n",
    "\n",
    "- **MedInc:**      Median-Einkommen\n",
    "- **HouseAge:**    Median-Hausalter\n",
    "- **AveRooms:**    Mittlere Zimmerzahl\n",
    "- **AveBedrms:**   Mittlere Schlafzimmerzahl  \n",
    "- **Population:**  Bevölkerungszahl\n",
    "- **AveOccup:**    Mittlere Bewohnerzahl der Häuser\n",
    "- **Latitude:**    Breitengrad\n",
    "- **Longitude:**   Längengrad \n",
    "\n",
    "Laden des California Housing Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e137a008-5f1c-4eb2-a417-4b5e929c1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "(X, y) = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "print(\"Dimension der Daten:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744abd0-a0a5-4fed-8218-58a44ed78f8e",
   "metadata": {},
   "source": [
    "## Aufgabe 1 (10 Punkte): \n",
    "\n",
    "Trainieren Sie nichtregularisierte Regressionsmodelle auf dem California Housing Datensatz:\n",
    "\n",
    "a) Trainieren Sie ein einfaches lineares Regressionsmodell __nur__ mit dem Feature Median-Hausalter. Plotten und evaluieren Sie das Modell. Was fällt Ihnen auf? Was könnte man verbessern?\n",
    "\n",
    "b) Trainieren Sie nun ein einfaches lineares Regressionsmodell basierend auf allen Features. Welche informationen erhalten Sie aus Trainings- & Testscore?\n",
    "\n",
    "c) Trainieren ein polynomiales Regressionsmodell vom Grad 2 und Grad 3 basierend auf allen Features. Was fällt Ihnen auf?\\\n",
    "**Bemerkung**:\\\n",
    "Bei polynomialer Regression mit mehr als einem Feature werden nicht nur die Potenzen einzelner Features sondern auch die jeweiligen Produkte unterschiedlicher Features betrachtet.\\\n",
    "Eine Hilfestellung zur Implementierung der polynomialen Regression können Sie z.B. hier finden:\\\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bd899-185f-448c-8f68-2f8ab96d4580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e2a51d-fe02-481d-a954-27c6b2cdcaa5",
   "metadata": {},
   "source": [
    "## Aufgabe 2 (10 Punkte):\n",
    "\n",
    "Trainieren Sie regularisierte Modelle auf dem California Housing Datensatz:\n",
    "\n",
    "a) Trainieren Sie ein Ridge Regression Modell und evaluieren Sie es. Wie erhalten Sie ein möglichst gutes und sinnvolles Modell? (Regularisierungsparameter? Lineare oder polynomiale Regression?) Was fällt Ihnen auf?\n",
    "\n",
    "b) Trainieren Sie ein Lasso Regression Modell und evaluieren Sie es. Wie erhalten Sie ein möglichst gutes und sinnvolles Modell? (Regularisierungsparameter? Lineare oder polynomiale Regression?) Was fällt Ihnen auf?\n",
    "\n",
    "c) Vergleichen Sie die verschiedenen Regressionsansätze, d.h. nichtregularisierte Regression (Methode der kleinsten Quadrate), Ridge Regression und Lasso Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b92a4b-0978-45ae-903a-148058833616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bf4805b-a08e-46a0-8352-a295f190768d",
   "metadata": {},
   "source": [
    "## Bonusaufgabe (10 Extrapunkte): \n",
    "\n",
    "Implementieren Sie die Ridge Regression von Hand. \n",
    "\n",
    "- Schreiben Sie eine Funktion, die Ridge Regression auf eingegebene Daten (Feature Matrix X und Labels y) anwendet (ohne zu Hilfenahme des Scikit Learn Pakets).\n",
    "- Wenden Sie Ridge Regression auf den generierten Wave-Datensatz an (siehe oben).\n",
    "- Probieren Sie die Kombination von polynomialer Regression (hierfür darf sklearn.preprocessing.PolynomialFeatures verwendet werden) mit Ridge Regression basierend auf dem oben generierten Wave-Datensatz.\n",
    "- Wie erhalten Sie die besten bzw. gute Ergebnisse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f14ce-9ecd-4885-8c80-64e873da3b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
